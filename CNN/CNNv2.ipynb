{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_fit_context' from 'sklearn.base' (c:\\Python311\\Lib\\site-packages\\sklearn\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_name, metric_name\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_random_state\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierLabelEncoder, RegressorTargetEncoder\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseWrapper\u001b[39;00m(BaseEstimator):\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of the scikit-learn classifier API for Keras.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Below are a list of SciKeras specific parameters. For details on other parameters,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m        The number of features seen during `fit`.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scikeras\\utils\\transformers.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer, OneHotEncoder, OrdinalEncoder\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerMixin, _fit_context, clone\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_fit_context' from 'sklearn.base' (c:\\Python311\\Lib\\site-packages\\sklearn\\base.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df= pd.read_csv('../input/gdz-elektrik-datathon/train.csv')\n",
    "# test_df= pd.read_csv('../input/gdz-elektrik-datathon/test.csv')\n",
    "# holidays_df = pd.read_csv('../input/gdz-elektrik-datathon/holidays.csv')\n",
    "# weather_df= pd.read_csv('../input/gdz-elektrik-datathon/weather.csv')\n",
    "train_df= pd.read_csv('./train.csv')\n",
    "test_df= pd.read_csv('./test.csv')\n",
    "holidays_df = pd.read_csv('./holidays.csv')\n",
    "weather_df= pd.read_csv('./weather.csv')\n",
    "\n",
    "train_df['tarih'] = pd.to_datetime(train_df['tarih'])\n",
    "train_df['ilce'] = train_df['ilce'].astype('category')\n",
    "train_df[\"bildirimsiz_sum\"] = train_df[\"bildirimsiz_sum\"].astype(int)\n",
    "train_df[\"bildirimli_sum\"] = train_df[\"bildirimli_sum\"].astype(int)\n",
    "\n",
    "test_df['tarih'] = pd.to_datetime(test_df['tarih'])\n",
    "test_df['ilce'] = test_df['ilce'].astype('category')\n",
    "test_df[\"bildirimli_sum\"] = test_df[\"bildirimli_sum\"].astype(int)\n",
    "\n",
    "holidays_df[\"tarih\"] = holidays_df['Yıl'].astype(str) + '-' + holidays_df['Ay'].astype(str) + '-' + holidays_df['Gün'].astype(str)\n",
    "holidays_df[\"tarih\"] = pd.to_datetime(holidays_df[\"tarih\"])\n",
    "holidays_df = holidays_df.drop(columns=['Yıl', 'Ay', 'Gün'])\n",
    "\n",
    "\n",
    "weather_df[\"tarih\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "weather_df['ilce'] = weather_df['name'].astype('category')\n",
    "weather_df = weather_df.drop(columns=['date','name'])\n",
    "#Train\n",
    "merged_train_df = pd.merge(train_df, holidays_df, on='tarih', how='left').reset_index()\n",
    "merged_train_df['Bayram_Flag'] = merged_train_df['Tatil Adı'].fillna(0)\n",
    "merged_train_df['Bayram_Flag'] = merged_train_df['Bayram_Flag'].astype('category')\n",
    "merged_train_df = merged_train_df.drop(columns=['Tatil Adı'])\n",
    "\n",
    "merged_train_df['is_Bayram'] = merged_train_df['Bayram_Flag'].apply(lambda x: 0 if x == 0 else 1)\n",
    "merged_train_df['is_Bayram'] = merged_train_df['Bayram_Flag'].astype(bool)\n",
    "merged_train_df['ilce']=merged_train_df['ilce'].astype('category')\n",
    "\n",
    "#Test\n",
    "merged_test_df = pd.merge(test_df, holidays_df, on='tarih', how='left').reset_index()\n",
    "merged_test_df['Bayram_Flag'] = merged_test_df['Tatil Adı'].fillna(0)\n",
    "merged_test_df['Bayram_Flag'] = merged_test_df['Bayram_Flag'].astype('category')\n",
    "merged_test_df = merged_test_df.drop(columns=['Tatil Adı'])\n",
    "\n",
    "merged_test_df['is_Bayram'] = merged_test_df['Bayram_Flag'].apply(lambda x: 0 if x == 0 else 1)\n",
    "merged_test_df['is_Bayram'] = merged_test_df['Bayram_Flag'].astype(bool)\n",
    "merged_test_df['ilce']=merged_test_df['ilce'].astype('category')\n",
    "#weather op\n",
    "daily_df = weather_df.groupby(['ilce', pd.Grouper(freq='D', key='tarih')])\n",
    "\n",
    "daily_df = daily_df.agg({\n",
    "    't_2m:C': ['max', 'min'],  # temperature\n",
    "    'prob_precip_1h:p': ['sum', 'max' ,'mean',lambda x: x.mode()[0]],  # precipitation\n",
    "    'wind_speed_10m:ms': ['max', 'mean','std',lambda x: x.mode()[0]],  # wind speed\n",
    "    'wind_dir_10m:d': 'mean',  # wind direction\n",
    "    'global_rad:W': 'sum',  # sunshine duration\n",
    "    'effective_cloud_cover:p': ['mean','std'],  # cloud cover\n",
    "    'relative_humidity_2m:p': ['max', 'min',lambda x: x.mode()[0]]  # humidity\n",
    "})\n",
    "\n",
    "daily_df.columns = ['_'.join(col).strip() for col in daily_df.columns.values]\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df = daily_df.rename(columns={col: col.replace('<lambda_0>', 'mode') for col in daily_df.columns})\n",
    "daily_df['ilce'] = daily_df['ilce'].str.lower()\n",
    "weather_df=daily_df\n",
    "\n",
    "#merging all\n",
    "merged_test_df = pd.merge(weather_df, merged_test_df, on=['tarih', 'ilce'], how='inner')\n",
    "merged_train_df = pd.merge(weather_df, merged_train_df, on=['tarih', 'ilce'], how='inner')\n",
    "\n",
    "merged_test_df['ilce'] = merged_test_df['ilce'].astype('category')\n",
    "merged_train_df['ilce'] = merged_train_df['ilce'].astype('category')\n",
    "\n",
    "merged_train_df = merged_train_df.drop(columns=['index'])\n",
    "merged_test_df = merged_test_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged Train ve Merged Test csv dosyalarına ulaşmak için aşağıdaki yeri çalıştırın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_train_df.to_excel(\"./merged_df/merged_train.xlsx\", index=False)\n",
    "# merged_test_df.to_excel(\"./merged_df/merged_test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1363 entries, 0 to 1362\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   ilce                          1363 non-null   category      \n",
      " 1   tarih                         1363 non-null   datetime64[ns]\n",
      " 2   t_2m:C_max                    1363 non-null   float64       \n",
      " 3   t_2m:C_min                    1363 non-null   float64       \n",
      " 4   prob_precip_1h:p_sum          1363 non-null   float64       \n",
      " 5   prob_precip_1h:p_max          1363 non-null   float64       \n",
      " 6   prob_precip_1h:p_mean         1363 non-null   float64       \n",
      " 7   prob_precip_1h:p_mode         1363 non-null   float64       \n",
      " 8   wind_speed_10m:ms_max         1363 non-null   float64       \n",
      " 9   wind_speed_10m:ms_mean        1363 non-null   float64       \n",
      " 10  wind_speed_10m:ms_std         1363 non-null   float64       \n",
      " 11  wind_speed_10m:ms_mode        1363 non-null   float64       \n",
      " 12  wind_dir_10m:d_mean           1363 non-null   float64       \n",
      " 13  global_rad:W_sum              1363 non-null   float64       \n",
      " 14  effective_cloud_cover:p_mean  1363 non-null   float64       \n",
      " 15  effective_cloud_cover:p_std   1363 non-null   float64       \n",
      " 16  relative_humidity_2m:p_max    1363 non-null   float64       \n",
      " 17  relative_humidity_2m:p_min    1363 non-null   float64       \n",
      " 18  relative_humidity_2m:p_mode   1363 non-null   float64       \n",
      " 19  bildirimli_sum                1363 non-null   int32         \n",
      " 20  Bayram_Flag                   1363 non-null   category      \n",
      " 21  is_Bayram                     1363 non-null   bool          \n",
      "dtypes: bool(1), category(2), datetime64[ns](1), float64(17), int32(1)\n",
      "memory usage: 213.2 KB\n"
     ]
    }
   ],
   "source": [
    "merged_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables=['t_2m:C_max', 't_2m:C_min', 'prob_precip_1h:p_sum',\n",
    "       'prob_precip_1h:p_max', 'prob_precip_1h:p_mean',\n",
    "       'prob_precip_1h:p_mode', 'wind_speed_10m:ms_max',\n",
    "       'wind_speed_10m:ms_mean', 'wind_speed_10m:ms_std',\n",
    "       'wind_speed_10m:ms_mode', 'wind_dir_10m:d_mean', 'global_rad:W_sum',\n",
    "       'effective_cloud_cover:p_mean', 'effective_cloud_cover:p_std',\n",
    "       'relative_humidity_2m:p_max', 'relative_humidity_2m:p_min',\n",
    "       'relative_humidity_2m:p_mode', 'bildirimli_sum','is_Bayram']\n",
    "dependent_variables= ['bildirimsiz_sum' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_standard = StandardScaler()\n",
    "#normalizing the values\n",
    "train_independent_variables_standardized = scaler_standard.fit_transform(merged_train_df[independent_variables])\n",
    "train_dependent_variables = merged_train_df[dependent_variables]\n",
    "test_independent_variables_standardized = scaler_standard.transform(merged_test_df[independent_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,641</span> (65.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,641\u001b[0m (65.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,641</span> (65.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,641\u001b[0m (65.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(train_independent_variables_standardized.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 32.4057 - val_loss: 26.7440\n",
      "Epoch 2/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 29.6340 - val_loss: 26.1525\n",
      "Epoch 3/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 27.9299 - val_loss: 25.3098\n",
      "Epoch 4/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 27.8265 - val_loss: 25.5503\n",
      "Epoch 5/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 27.2113 - val_loss: 25.5438\n",
      "Epoch 6/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 27.2073 - val_loss: 25.7030\n",
      "Epoch 7/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 27.1241 - val_loss: 25.4144\n",
      "Epoch 8/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 27.2044 - val_loss: 26.3215\n",
      "Epoch 9/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 27.8350 - val_loss: 26.4334\n",
      "Epoch 10/10\n",
      "\u001b[1m1204/1204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 27.9477 - val_loss: 25.4176\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit(train_independent_variables_standardized, train_dependent_variables,\n",
    "                    epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Predictions shape: (1363, 1)\n"
     ]
    }
   ],
   "source": [
    "#testing the model \n",
    "predictions = model.predict(test_independent_variables_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(learning_rate, dropout_rate, filters, kernel_size, dense_units, batch_size,num_conv_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(train_independent_variables_standardized.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    for _ in range(num_conv_layers-1):\n",
    "        model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, <function create_model at 0x000001E97F271300> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[0;32m     12\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mcreate_model,param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_independent_variables_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dependent_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:776\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(refit):\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;66;03m# If callable, refit is expected to return the index of the best\u001b[39;00m\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;66;03m# parameter set.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m     best_index \u001b[38;5;241m=\u001b[39m refit(results)\n\u001b[1;32m--> 776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(best_index, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m    777\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_index_ returned is not an integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m best_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:474\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    440\u001b[0m def _check_multimetric_scoring(estimator, scoring):\n\u001b[0;32m    441\u001b[0m     \"\"\"Check the scoring parameter in cases when multiple metrics are allowed.\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m     In addition, multimetric scoring leverages a caching mechanism to not call the same\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m         A dict mapping each scorer name to its validated scorer.\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     err_msg_generic = (\n\u001b[0;32m    471\u001b[0m         f\"scoring is invalid (got {scoring!r}). Refer to the \"\n\u001b[0;32m    472\u001b[0m         \"scoring glossary for details: \"\n\u001b[0;32m    473\u001b[0m         \"https://scikit-learn.org/stable/glossary.html#term-scoring\"\n\u001b[1;32m--> 474\u001b[0m     )\n\u001b[0;32m    476\u001b[0m     if isinstance(scoring, (list, tuple, set)):\n\u001b[0;32m    477\u001b[0m         err_msg = (\n\u001b[0;32m    478\u001b[0m             \"The list/tuple elements must be unique strings of predefined scorers. \"\n\u001b[0;32m    479\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <function create_model at 0x000001E97F271300> was passed"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'num_conv_layers': [1, 2, 3],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    'filters': [64, 128, 256],\n",
    "    'kernel_size': [3, 5, 7],\n",
    "    'dense_units': [128, 256, 512],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=create_model,param_grid=param_grid, cv=5, scoring='mean_squared_error', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(train_independent_variables_standardized, train_dependent_variables)\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(train_independent_variables_standardized, train_dependent_variables, epochs=10, batch_size=best_model.batch_size, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = best_model.evaluate(test_independent_variables_standardized, merged_test_df[dependent_variables])\n",
    "print(\"Test loss:\", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
