{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weather_data(daily_weather):\n",
    "        \n",
    "        daily_weather['tarih'] = pd.to_datetime(daily_weather['tarih'])\n",
    "        daily_weather['day'] = daily_weather['tarih'].dt.date\n",
    "        daily_weather['hour'] = daily_weather['tarih'].dt.hour\n",
    "\n",
    "\n",
    "        daily_weather = daily_weather.groupby(['ilce', pd.Grouper(freq='D', key='tarih')])\n",
    "        ## Apply the aggregations\n",
    "        daily_weather= daily_weather.agg({\n",
    "            't_2m:C': ['max', 'min', 'mean','std'],  # temperature\n",
    "            'prob_precip_1h:p': ['sum', 'max' ,'mean'],  # precipitation\n",
    "            'wind_speed_10m:ms': ['max', 'mean','std'],  # wind speed\n",
    "            'wind_dir_10m:d': 'mean',  # wind direction\n",
    "            'global_rad:W': 'sum',  # sunshine duration\n",
    "            'effective_cloud_cover:p': ['mean','std'],  # cloud cover\n",
    "            'relative_humidity_2m:p': ['max', 'min', 'mean']  # humidity\n",
    "        })\n",
    "\n",
    "        # Flatten the MultiIndex columns\n",
    "        daily_weather.columns = ['_'.join(col).strip() for col in daily_weather.columns.values]\n",
    "        daily_weather= daily_weather.reset_index() \n",
    "        return daily_weather\n",
    "def create_unique_id(df):\n",
    "    df['unique_id'] = df['tarih'].astype(str) +  '-' +df['ilce'].astype(str) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train= pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "weather = pd.read_csv(\"weather.csv\")\n",
    "holidays = pd.read_csv(\"holidays.csv\")\n",
    "\n",
    "# \"date\" sütununu \"tarih\" olarak değiştirme\n",
    "weather.rename(columns={\"date\": \"tarih\"}, inplace=True)\n",
    "weather.rename(columns={\"name\": \"ilce\"}, inplace=True)\n",
    "\n",
    "print(weather.keys)\n",
    "# Tüm ilçe isimlerini küçük harfe dönüştür\n",
    "weather[\"ilce\"] = weather[\"ilce\"].str.lower()\n",
    "train[\"ilce\"] = train[\"ilce\"].str.lower()\n",
    "test[\"ilce\"] = test[\"ilce\"].str.lower()\n",
    "\n",
    "print(len(test))\n",
    "print(len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.read_csv('holidays.csv')\n",
    "holidays.columns =['year', 'month' ,'day' , 'holiday']\n",
    "add_columns = holidays['holiday']\n",
    "# Create a new column for each unique holiday name\n",
    "\n",
    "holidays['tarih'] = pd.to_datetime(holidays[['year', 'month', 'day']])\n",
    "for new in holidays['holiday'].unique():\n",
    "    holidays[new] = (holidays['holiday'] == new).astype(int)\n",
    "holidays.drop(['holiday', 'year', 'month', 'day'] , axis=1 , inplace=True)\n",
    "holidays.columns\n",
    "holidays.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.rename(columns={'date': 'tarih','name':'ilce'}, inplace=True)\n",
    "weather = aggregate_weather_data(weather)\n",
    "#weather = create_unique_id(weather)\n",
    "#weather['unique_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "after_date = datetime(2024, 2, 1)\n",
    "# train data buraya baslangictan 2024/2/01'a kadar olacak\n",
    "weather_train = weather[weather['tarih'] < after_date]\n",
    "holidays_train = holidays[holidays['tarih'] < after_date]\n",
    "\n",
    "# test data buraya sadece asagidaki tarihten itibaren olacak\n",
    "weather_test = weather[weather['tarih'] >= after_date ]\n",
    "holidays_test = holidays[holidays['tarih'] >= after_date]\n",
    "len(weather_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARADA BOSLUK GUNLER VAR ONLARI MEAN ILE DOLDURDUK SORUN OLABILIR TABI AMA OLSUN\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "columns_to_impute = ['bildirimsiz_sum', 'bildirimli_sum']\n",
    "\n",
    "# Create a simple imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer to the data\n",
    "imputer.fit(train[columns_to_impute])\n",
    "\n",
    "# Impute the missing values\n",
    "train[columns_to_impute] = imputer.transform(train[columns_to_impute])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['tarih' , 'ilce' , 'bildirimsiz_sum', 'bildirimli_sum']\n",
    "#train = create_unique_id(train)\n",
    "train['tarih'] = pd.to_datetime(train['tarih'])\n",
    " #Process data and train model\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns= ['tarih','ilce','bildirimli_sum']\n",
    "#test = create_unique_id(test)\n",
    "test.head()\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##@@@ test ops train ops\n",
    "test['tarih'] = pd.to_datetime(test['tarih'])\n",
    "\n",
    "test['days_in_month'] = test['tarih'].dt.days_in_month\n",
    "test['days_in_year'] = test['tarih'].dt.day_of_year\n",
    "test['days_in_week'] = test['tarih'].dt.weekday\n",
    "test['month'] = test['tarih'].dt.month\n",
    "test['year'] = test['tarih'].dt.year\n",
    "\n",
    "train['tarih'] = pd.to_datetime(train['tarih'])\n",
    "\n",
    "train['days_in_month'] = train['tarih'].dt.days_in_month\n",
    "train['days_in_year'] = train['tarih'].dt.day_of_year\n",
    "train['days_in_week'] = train['tarih'].dt.weekday\n",
    "train['month'] = train['tarih'].dt.month\n",
    "train['year'] = train['tarih'].dt.year\n",
    "\n",
    "\n",
    "# Tarih sütunlarının formatlarını uygun hale getir\n",
    "weather[\"tarih\"] = pd.to_datetime(weather[\"tarih\"])\n",
    "train[\"tarih\"] = pd.to_datetime(train[\"tarih\"])\n",
    "test[\"tarih\"] = pd.to_datetime(test[\"tarih\"])\n",
    "max(test['tarih'])\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train['ilce'])\n",
    "# Transform both datasets using the same encoder\n",
    "train['ilce-value'] = label_encoder.transform(train['ilce'])\n",
    "test['ilce-value'] = label_encoder.transform(test['ilce'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ilce and tarih as the index\n",
    "test.set_index(['ilce', 'tarih'], inplace=True)\n",
    "weather_test.set_index(['ilce', 'tarih'], inplace=True)\n",
    "train.set_index(['ilce', 'tarih'], inplace=True)\n",
    "weather_train.set_index(['ilce', 'tarih'], inplace=True)\n",
    "\n",
    "# Merge the dataframes\n",
    "test_df = pd.merge(test, weather_test, on=['ilce', 'tarih'])\n",
    "train_df = pd.merge(train, weather_train, on=['ilce', 'tarih'])\n",
    "train_df = pd.merge(train, weather_train, left_index=True, right_index=True)\n",
    "len(test_df)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Weather data and merging them into train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_values = train_df.index.get_level_values('tarih')\n",
    "train_df['tarih-value'] = pd.factorize(train_index_values)[0]\n",
    "max_train_tarih = max(train_df['tarih-value'])\n",
    "\n",
    "test_index_values = test_df.index.get_level_values('tarih')\n",
    "test_df['tarih-value'] = pd.factorize(test_index_values)[0] + max_train_tarih + 1\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Hedef değişkeni ve özellikleri ayır\n",
    "X = train_df.drop(columns=[\"bildirimsiz_sum\"])\n",
    "y = train_df[\"bildirimsiz_sum\"]\n",
    "\n",
    "corr = train_df.corr()\n",
    "target_corr = abs(corr[\"bildirimsiz_sum\"])\n",
    "corr_threshold = 0.02\n",
    "high_corr_features = target_corr[target_corr > corr_threshold]\n",
    "# özellik isimlerini alalım ve bildirimsiz_sum özelliğini çıkaralım\n",
    "hcf_names = [k for k, v in high_corr_features.items()]; hcf_names.remove(\"bildirimsiz_sum\")\n",
    "#print(hcf_names)\n",
    "features= ['bildirimli_sum', 'days_in_month', 'days_in_year',\n",
    "       'days_in_week', 'month', 'year', 't_2m:C_max', 't_2m:C_min',\n",
    "       't_2m:C_mean', 't_2m:C_std', 'prob_precip_1h:p_sum',\n",
    "       'prob_precip_1h:p_max', 'prob_precip_1h:p_mean',\n",
    "       'wind_speed_10m:ms_max', 'wind_speed_10m:ms_mean',\n",
    "       'wind_speed_10m:ms_std', 'wind_dir_10m:d_mean', 'global_rad:W_sum',\n",
    "       'effective_cloud_cover:p_mean', 'effective_cloud_cover:p_std',\n",
    "       'relative_humidity_2m:p_max', 'relative_humidity_2m:p_min',\n",
    "       'relative_humidity_2m:p_mean', 'tarih-value', 'ilce-value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[features]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Model oluşturma\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# GridSearchCV ile en iyi parametre kombinasyonunun bulunması\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, n_jobs=1, verbose=2)\n",
    "grid_search.fit(X,y)\n",
    "#njobs -1 olmali (benim makinem paralel calismiyor cunku )\n",
    "# En iyi parametrelerin bulunması\n",
    "best_params = grid_search.best_params_\n",
    "print(\"En iyi parametreler:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGBoost modelini eğitme\n",
    "xgboost_model = XGBRegressor(**best_params)\n",
    "xgboost_model.fit(train_df[features],y)\n",
    "\n",
    "# CatBoost modelini eğitme\n",
    "catboost_model = CatBoostRegressor()\n",
    "catboost_model.fit(train_df[features],y)\n",
    "\n",
    "# Tahminler yapma\n",
    "\n",
    "\n",
    "\n",
    "X_test = test_df[features]\n",
    "X_test['ilce'] = label_encoder.fit_transform(X_test['ilce'])\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#catboost_preds = catboost_model.predict(X_test)\n",
    "xgboost_preds = xgboost_model.predict(X_test)\n",
    "catboost_preds = catboost_model.predict(X_test)\n",
    "print(\"----------------------------------\")\n",
    "print(len(X_test))\n",
    "print(catboost_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensemble_preds = (catboost_preds + xgboost_preds) / 2\n",
    "ensemble_preds=np.round(catboost_preds).astype(np.int8)\n",
    "# Sample submission dosyasına tahminleri ekleyerek yeni bir dosya oluşturma\n",
    "submission = sample_submission.copy()\n",
    "print(ensemble_preds)\n",
    "submission[\"bildirimsiz_sum\"] = ensemble_preds\n",
    "submission.to_csv(\"ensemble3_submission.csv\", index=False)\n",
    "#model2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
