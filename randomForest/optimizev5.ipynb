{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./gdz-elektrik-datathon-2024/train.csv')\n",
    "test_df = pd.read_csv('./gdz-elektrik-datathon-2024/test.csv')\n",
    "holidays_df = pd.read_csv('./gdz-elektrik-datathon-2024/holidays.csv')\n",
    "weather_df = pd.read_csv('./gdz-elektrik-datathon-2024/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simaa\\AppData\\Local\\Temp\\ipykernel_38368\\1277616972.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_test_df['Bayram_Flag'] = merged_test_df['Tatil AdÄ±'].fillna(0)\n",
      "C:\\Users\\simaa\\AppData\\Local\\Temp\\ipykernel_38368\\1277616972.py:38: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  daily_df = weather_df.groupby(['ilce', pd.Grouper(freq='D', key='tarih')])\n"
     ]
    }
   ],
   "source": [
    "train_df['tarih'] = pd.to_datetime(train_df['tarih'])\n",
    "train_df['ilce'] = train_df['ilce'].astype('category')\n",
    "train_df[\"bildirimsiz_sum\"] = train_df[\"bildirimsiz_sum\"].astype(np.int8)\n",
    "train_df[\"bildirimli_sum\"] = train_df[\"bildirimli_sum\"].astype(np.int8)\n",
    "\n",
    "test_df['tarih'] = pd.to_datetime(test_df['tarih'])\n",
    "test_df['ilce'] = test_df['ilce'].astype('category')\n",
    "test_df[\"bildirimli_sum\"] = test_df[\"bildirimli_sum\"].astype(np.int8)\n",
    "\n",
    "holidays_df[\"tarih\"] = holidays_df['YÄ±l'].astype(str) + '-' + holidays_df['Ay'].astype(str) + '-' + holidays_df['GÃ¼n'].astype(str)\n",
    "holidays_df[\"tarih\"] = pd.to_datetime(holidays_df[\"tarih\"])\n",
    "holidays_df = holidays_df.drop(columns=['YÄ±l', 'Ay', 'GÃ¼n'])\n",
    "\n",
    "\n",
    "weather_df[\"tarih\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "weather_df['ilce'] = weather_df['name'].astype('category')\n",
    "weather_df = weather_df.drop(columns=['date','name'])\n",
    "#Train\n",
    "merged_train_df = pd.merge(train_df, holidays_df, on='tarih', how='left').reset_index()\n",
    "merged_train_df['Bayram_Flag'] = merged_train_df['Tatil AdÄ±'].fillna(0)\n",
    "merged_train_df['Bayram_Flag'] = merged_train_df['Bayram_Flag'].astype('category')\n",
    "merged_train_df = merged_train_df.drop(columns=['Tatil AdÄ±'])\n",
    "\n",
    "merged_train_df['is_Bayram'] = merged_train_df['Bayram_Flag'].apply(lambda x: 0 if x == 0 else 1)\n",
    "merged_train_df['is_Bayram'] = merged_train_df['Bayram_Flag'].astype(bool)\n",
    "merged_train_df['ilce']=merged_train_df['ilce'].astype('category')\n",
    "\n",
    "#Test\n",
    "merged_test_df = pd.merge(test_df, holidays_df, on='tarih', how='left').reset_index()\n",
    "merged_test_df['Bayram_Flag'] = merged_test_df['Tatil AdÄ±'].fillna(0)\n",
    "merged_test_df['Bayram_Flag'] = merged_test_df['Bayram_Flag'].astype('category')\n",
    "merged_test_df = merged_test_df.drop(columns=['Tatil AdÄ±'])\n",
    "\n",
    "merged_test_df['is_Bayram'] = merged_test_df['Bayram_Flag'].apply(lambda x: 0 if x == 0 else 1)\n",
    "merged_test_df['is_Bayram'] = merged_test_df['Bayram_Flag'].astype(bool)\n",
    "merged_test_df['ilce']=merged_test_df['ilce'].astype('category')\n",
    "#weather op\n",
    "daily_df = weather_df.groupby(['ilce', pd.Grouper(freq='D', key='tarih')])\n",
    "\n",
    "daily_df = daily_df.agg({\n",
    "    't_2m:C': ['max', 'min'],  # temperature\n",
    "    'prob_precip_1h:p': ['sum', 'max' ,'mean',lambda x: x.mode()[0]],  # precipitation\n",
    "    'wind_speed_10m:ms': ['max', 'mean','std',lambda x: x.mode()[0]],  # wind speed\n",
    "    'wind_dir_10m:d': 'mean',  # wind direction\n",
    "    'global_rad:W': 'sum',  # sunshine duration\n",
    "    'effective_cloud_cover:p': ['mean','std'],  # cloud cover\n",
    "    'relative_humidity_2m:p': ['max', 'min',lambda x: x.mode()[0]]  # humidity\n",
    "})\n",
    "\n",
    "daily_df.columns = ['_'.join(col).strip() for col in daily_df.columns.values]\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df = daily_df.rename(columns={col: col.replace('<lambda_0>', 'mode') for col in daily_df.columns})\n",
    "daily_df['ilce'] = daily_df['ilce'].str.lower()\n",
    "weather_df=daily_df\n",
    "\n",
    "#merging all\n",
    "merged_test_df = pd.merge(weather_df, merged_test_df, on=['tarih', 'ilce'], how='inner')\n",
    "merged_train_df = pd.merge(weather_df, merged_train_df, on=['tarih', 'ilce'], how='inner')\n",
    "\n",
    "merged_train_df['ilce']=merged_train_df['ilce'].astype('category')\n",
    "merged_test_df['ilce']=merged_test_df['ilce'].astype('category')\n",
    "\n",
    "covariance = merged_train_df.select_dtypes(include=['float64', 'int8','bool']).cov()['bildirimsiz_sum']\n",
    "correlation = merged_train_df.select_dtypes(include=['float64', 'int8','bool']).corr()[\"bildirimsiz_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ilce                                  category\n",
       "tarih                           datetime64[ns]\n",
       "t_2m:C_max                             float64\n",
       "t_2m:C_min                             float64\n",
       "prob_precip_1h:p_sum                   float64\n",
       "prob_precip_1h:p_max                   float64\n",
       "prob_precip_1h:p_mean                  float64\n",
       "prob_precip_1h:p_mode                  float64\n",
       "wind_speed_10m:ms_max                  float64\n",
       "wind_speed_10m:ms_mean                 float64\n",
       "wind_speed_10m:ms_std                  float64\n",
       "wind_speed_10m:ms_mode                 float64\n",
       "wind_dir_10m:d_mean                    float64\n",
       "global_rad:W_sum                       float64\n",
       "effective_cloud_cover:p_mean           float64\n",
       "effective_cloud_cover:p_std            float64\n",
       "relative_humidity_2m:p_max             float64\n",
       "relative_humidity_2m:p_min             float64\n",
       "relative_humidity_2m:p_mode            float64\n",
       "index                                    int64\n",
       "bildirimsiz_sum                           int8\n",
       "bildirimli_sum                            int8\n",
       "Bayram_Flag                           category\n",
       "is_Bayram                                 bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['bildirimsiz_sum'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m merged_train_df[features]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbildirimsiz_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m y_train \u001b[38;5;241m=\u001b[39m merged_train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbildirimsiz_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 10\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_test_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# UlaÅŸtÄ±ÄŸÄ±m en uygun parametreler ðŸ “ðŸ “ðŸ “ðŸ “ðŸ “\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\simaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\simaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\simaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['bildirimsiz_sum'] not in index\""
     ]
    }
   ],
   "source": [
    "features = [\"t_2m:C_max\", \"t_2m:C_min\", \"prob_precip_1h:p_sum\", \"prob_precip_1h:p_max\",\n",
    "            \"wind_speed_10m:ms_max\", \"wind_speed_10m:ms_mean\", \"wind_speed_10m:ms_std\",\n",
    "            \"wind_dir_10m:d_mean\", \"global_rad:W_sum\", \"effective_cloud_cover:p_mean\",\n",
    "            \"effective_cloud_cover:p_std\", \"relative_humidity_2m:p_max\", \"relative_humidity_2m:p_min\",\n",
    "             \"is_Bayram\",\"bildirimsiz_sum\"]\n",
    "\n",
    "X_train = merged_train_df[features]\n",
    "y_train = merged_train_df[\"bildirimsiz_sum\"]\n",
    "\n",
    "X_test = merged_test_df[features]\n",
    "\n",
    "# UlaÅŸtÄ±ÄŸÄ±m en uygun parametreler ðŸ “ðŸ “ðŸ “ðŸ “ðŸ “\n",
    "model = RandomForestClassifier(n_estimators=160, max_depth=1, min_samples_split=4, min_samples_leaf=4) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(X_train, X_test)\n",
    "print(\"Test verileri Ã¼zerinde doÄŸruluk skoru:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
